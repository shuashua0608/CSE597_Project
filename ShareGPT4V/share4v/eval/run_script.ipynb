{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093e3c5f-773d-40ea-9ae8-7da595f24918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/bbmr/syang7/.conda/envs/share4v/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-08 23:24:26,043] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /u/syang7/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_rwlock_unlock'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_spin_init'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_spin_unlock'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_rwlock_init'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_rwlock_rdlock'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_spin_lock'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_spin_destroy'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_rwlock_destroy'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `pthread_rwlock_wrlock'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from share4v.constants import (DEFAULT_IM_END_TOKEN, DEFAULT_IM_START_TOKEN,\n",
    "                               DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX)\n",
    "from share4v.conversation import SeparatorStyle, conv_templates\n",
    "from share4v.mm_utils import (KeywordsStoppingCriteria,\n",
    "                              get_model_name_from_path, tokenizer_image_token)\n",
    "from share4v.model.builder import load_pretrained_model\n",
    "from share4v.utils import disable_torch_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ead487a-14ef-4393-baa2-a7efb1fbfc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(image_file):\n",
    "    if image_file.startswith('http') or image_file.startswith('https'):\n",
    "        response = requests.get(image_file)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    return image\n",
    "\n",
    "\n",
    "def eval_model(args):\n",
    "    # Model\n",
    "    disable_torch_init()\n",
    "\n",
    "    model_name = get_model_name_from_path(args.model_path)\n",
    "    tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "        args.model_path, args.model_base, model_name)\n",
    "\n",
    "    qs = args.query\n",
    "    if model.config.mm_use_im_start_end:\n",
    "        qs = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + \\\n",
    "            DEFAULT_IM_END_TOKEN + '\\n' + qs\n",
    "    else:\n",
    "        qs = DEFAULT_IMAGE_TOKEN + '\\n' + qs\n",
    "\n",
    "    if 'llama-2' in model_name.lower():\n",
    "        conv_mode = \"share4v_llama_2\"\n",
    "    elif \"v1\" in model_name.lower():\n",
    "        conv_mode = \"share4v_v1\"\n",
    "    elif \"mpt\" in model_name.lower():\n",
    "        conv_mode = \"mpt\"\n",
    "    else:\n",
    "        conv_mode = \"share4v_v0\"\n",
    "\n",
    "    if args.conv_mode is not None and conv_mode != args.conv_mode:\n",
    "        print('[WARNING] the auto inferred conversation mode is {}, while `--conv-mode` is {}, using {}'.format(\n",
    "            conv_mode, args.conv_mode, args.conv_mode))\n",
    "    else:\n",
    "        args.conv_mode = conv_mode\n",
    "\n",
    "    conv = conv_templates[args.conv_mode].copy()\n",
    "    conv.append_message(conv.roles[0], qs)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "\n",
    "    images = load_image(args.image_file)\n",
    "    images_tensor = image_processor.preprocess(images, return_tensors='pt')[\n",
    "        'pixel_values'].half().cuda()\n",
    "\n",
    "    input_ids = tokenizer_image_token(\n",
    "        prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    keywords = [stop_str]\n",
    "    stopping_criteria = KeywordsStoppingCriteria(\n",
    "        keywords, tokenizer, input_ids)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            images=images_tensor,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            max_new_tokens=1024,\n",
    "            use_cache=True,\n",
    "            stopping_criteria=[stopping_criteria])\n",
    "\n",
    "    input_token_len = input_ids.shape[1]\n",
    "    n_diff_input_output = (\n",
    "        input_ids != output_ids[:, :input_token_len]).sum().item()\n",
    "    if n_diff_input_output > 0:\n",
    "        print(\n",
    "            f'[Warning] {n_diff_input_output} output_ids are not the same as the input_ids')\n",
    "    outputs = tokenizer.batch_decode(\n",
    "        output_ids[:, input_token_len:], skip_special_tokens=True)[0]\n",
    "    outputs = outputs.strip()\n",
    "    if outputs.endswith(stop_str):\n",
    "        outputs = outputs[:-len(stop_str)]\n",
    "    outputs = outputs.strip()\n",
    "    print(outputs)\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # Obtain the model's output logits or embeddings\n",
    "        output = model(\n",
    "            input_ids=input_ids,\n",
    "            images=images_tensor,\n",
    "            return_dict=True,\n",
    "            output_hidden_states=True  # Ensure hidden states are returned\n",
    "        )\n",
    "    last_hidden_states = output.hidden_states[-1]  # Assuming this is the last layer\n",
    "\n",
    "    # Optionally, you can pool these features or use them as is\n",
    "    pooled_features = last_hidden_states.mean(dim=1)  # Simple example of pooling\n",
    "    # Return or save the features\n",
    "    return pooled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716717a3-b8ba-4903-b6a6-f5738fdc7b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vision tower from Lin-Chen/ShareGPT4V-7B_Pretrained_vit-large336-l12\n",
      "This is an impressionist painting that captures a serene scene of a river. The painting is dominated by a palette of greens, blues, and browns, which are used to depict the water, trees, and boats. The artist has employed a loose, sketchy style, focusing on the interplay of light and shadow to create a sense of depth and movement. The boats, painted in a darker shade of brown, are positioned in the foreground, drawing the viewer's attention. The background features a lighter shade of green, with trees and buildings subtly visible, adding to the overall tranquility of the scene. The artist's use of color and light creates a harmonious balance, reflecting the peaceful atmosphere of the river.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Lin-Chen/ShareGPT4V-7B\"\n",
    "prompt = \"Please write a paragraph of formal art analysis for this painting\"\n",
    "image_file = '/scratch/bbmr/syang7/art/dataset_new/Manet/EM_15.jpg'\n",
    "\n",
    "args = type('Args', (), {\n",
    "    \"model_path\": model_path,\n",
    "    \"model_base\": None,\n",
    "    \"model_name\": get_model_name_from_path(model_path),\n",
    "    \"query\": prompt,\n",
    "    \"conv_mode\": None,\n",
    "    \"image_file\": image_file,\n",
    "    \"sep\": \",\",\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": None,\n",
    "    \"num_beams\": 1,\n",
    "    \"max_new_tokens\": 512\n",
    "})()\n",
    "\n",
    "pooled_features = eval_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2289db-6db7-44fd-9d2e-c9a14c245083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1 = torch.load('../../../../../GalleryGPT/GalleryGPT/comments_raw_features/Manet/EM_15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2487e73b-eb7f-41a6-9fd1-3343372fb6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2328,  0.1823, -0.2034,  ...,  0.5649, -0.8965,  0.1780]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb37944-4d18-41da-8821-1ce7bbd1ae9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4070, -0.7573,  0.6772,  ..., -0.2795,  0.3252, -0.4282]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "share4v",
   "language": "python",
   "name": "share4v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
